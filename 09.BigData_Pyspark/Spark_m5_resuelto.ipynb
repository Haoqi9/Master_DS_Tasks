{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c2ff46d-a1c7-4e9d-9c86-3cbc90758a0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Alumno: Hao, Qi Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68f7d09f-baee-41fd-8a5b-425e94578b45",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eee3c8df24c0920c7be7faf65104d0bf",
     "grade": false,
     "grade_id": "cell-f8987996be9f1238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Vídeos que fueron tendencia en YouTube\n",
    "\n",
    "### Disponible en Kaggle en:\n",
    "https://www.kaggle.com/datasnaek/youtube-new\n",
    "\n",
    "\n",
    "YouTube, el sitio web para compartir videos de fama mundial, mantiene una lista de los mejores videos de tendencias en la plataforma. Según la revista Variety, *Para determinar los videos más populares del año, YouTube utiliza una combinación de factores que incluyen la medición de las interacciones de los usuarios (número de visitas, compartidos, comentarios y me gusta). No son necesariamente los vídeos más vistos del año en general*. Los que se sitúan en la parte más alta de la lista de tendencias de YouTube suelen ser o bien vídeos musicales (como el famoso \"Gagnam Style\"), actuaciones de *celibrities* y / o reality shows, y vídeos virales variados de una persona aleatoria, cámara en mano.\n",
    "\n",
    "Este conjunto de datos es un registro diario de los videos más populares de YouTube. Incluye varios meses de datos en vídeos de tendencias diarias de YouTube. Se incluyen datos para las regiones de EEUU, Reino Unido, Dinamarca, Canadá y Francia con hasta 200 videos de tendencias listados por día. Aquí solo usaremos los de EEUU, Canadá y Reino Unido. Los datos de cada país están en un archivo separado. Las variables incluyen el título del video, título del canal, tiempo de publicación, etiquetas, vistas, me gusta y no me gusta, descripción y recuento de comentarios. Se recopiló utilizando la API de YouTube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd5efa48-3a28-49df-ba98-20ed071a7c25",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6b4dc108ddf890c659e33701965428",
     "grade": false,
     "grade_id": "cell-f74d7bfd01811789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Variables y significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44ab83f-363f-4a4d-a88a-b7eb1b7273fd",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b10e97ef91e0ae368718feaaf3c3137",
     "grade": false,
     "grade_id": "cell-9cfb34982bd4eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Las variables utilizadas para describir cada vídeo son:\n",
    "\n",
    "* video_id (string) ID único. Se ha asignado un video en la plataforma de YouTube. \n",
    "* trending_date (string) La fecha en que el video era tendencia \n",
    "* title (string) Título del vídeo\n",
    "* channel_title (string) Título del canal de publicación en la categoría de plataforma\n",
    "* category_id (string) El tipo de categoría del vídeo\n",
    "* publish_time (string) La fecha de publicación del vídeo \n",
    "* tags (string) Etiquetas asociadas al vídeo, separadas por |\n",
    "* views (entero) Número total de vistas en el vídeo.\n",
    "* likes (entero) Número de Me gusta en el vídeo\n",
    "* dislikes (entero) Número de No me gusta en el vídeo\n",
    "* comment_count (entero) Un recuento total de comentarios en el video \n",
    "* comments_disabled (booleano) Si los comentarios estaban desactivados (true) o activados (false) en el video \n",
    "* ratings_disabled (booleano) Si la opción de dar me gusta o no al video está deshabilitada (true), en cuyo caso el número de  Me gusta y de No me gusta será 0. \n",
    "* video_error_or_removed (booleano) Si el video tiene algún error o se eliminó después de cargar el país\n",
    "* description (string): Descripción textual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d95367-1075-4153-87cd-14eafabd0940",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Nombre completo del alumno:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00cae8a5-7d2b-4bc1-9d95-066449994606",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3821f9090a3fe8312fb5f67097a7a9d2",
     "grade": false,
     "grade_id": "cell-b4f9c37a2b92d2e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# INSTRUCCIONES\n",
    "\n",
    "En cada celda debes responder a la pregunta formulada, asegurándote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del cálculo quede guardado exactamente en la variable que venía inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). \n",
    "\n",
    "**No olvides borrar la línea *raise NotImplementedError()* de cada celda cuando hayas completado la solución de esa celda y quieras probarla**.\n",
    "\n",
    "Después de cada celda evaluable verás una celda con código. Ejecútala (no modifiques su código) y te dirá si tu solución es correcta o no. En caso de ser correcta, se ejecutará correctamente y no mostrará nada, pero si no lo es mostrará un error. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no. Asegúrate de que, al menos, todas las celdas indican que el código es correcto antes de enviar el notebook terminado.\n",
    "\n",
    "**Nunca se debe redondear ninguna cantidad si no lo pide explícitamente el enunciado**\n",
    "\n",
    "### Cada solución debe escribirse obligatoriamente en la celda habilitada para ello. Cualquier celda adicional que se haya creado durante el desarrollo deberá ser eliminada.\n",
    "\n",
    "Si necesitas crear celdas auxiliares durante el desarrollo, puedes hacerlo pero debes asegurarte de borrarlas antes de entregar el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c199b5bc-f41d-42f8-85e8-283770a6356a",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c1f80078dab9ae1c71185cfb397a81e",
     "grade": false,
     "grade_id": "cell-69ec0993eeaff3ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sobre los datasets youtube_USvideos.csv, youtube_CAvideos, youtube_GBvideos.csv se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ededdc9-3a16-415c-8415-0e8a22a6b0dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 1\n",
    "\n",
    "* Leer cada uno de estos ficheros en una variable, **sin intentar** que Spark infiera el tipo de dato de cada columna\n",
    "* Puesto que existen columnas que contienen una coma enmedio del valor, en esos casos los valores vienen entre comillas dobles. Spark ya contempla esta posibilidad y puede leerlas adecuadamente **si al leer le indicamos las siguientes opciones adicionales** además de las que ya sueles usar: `.option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\")`.\n",
    "* Asegúrate de que las **filas que no tienen el formato correcto sean descartadas**, indicando también la opción `mode` con el valor `DROPMALFORMED` como vimos en clase.\n",
    "* Encadenadas con la operación de lectura `.csv()` de cada fichero, añadir para cada uno de los ficheros:\n",
    "  - Una transformación para crear una nueva columna `pais` con una constante de tipo string (utiliza la función `F.lit(\"valor\")`) indicando el país, que debe tomar como valores `\"EEUU\"`, `\"CA\"` y `\"GB\"` para EEUU, Canadá y Gran Bretaña respectivamente. Dicho valor será igual para todas las filas de cada uno de los tres DF, pero distinto de un DF a otro.\n",
    "  * Una transformación que elimine la columna `description`, la cual contiene un texto que no analizaremos.\n",
    "* Crear finalmente un nuevo DF `videosRawDF` en el que se hayan unido los tres DF anteriores. No debe ser cacheado todavía puesto que vamos a realizar operaciones de limpieza más adelante, y trabajaremos a partir de entonces con otro DF resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf45f552-c1d9-4994-a518-4aac4e056386",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b1cc0e0ae5b216c4e818d01d9378a7a",
     "grade": false,
     "grade_id": "read_csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# LÍNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\n",
    "USvideosDF  = None\n",
    "CAvideosDF  = None\n",
    "videosRawDF = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "USvideosDF = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .option(\"quote\", \"\\\"\")\n",
    "         .option(\"escape\", \"\\\"\")\n",
    "         .csv(\"abfss://datos@masterhaoqx001sta.dfs.core.windows.net/youtube_USvideos.csv\")\n",
    "         .withColumn(\"pais\", F.lit(\"EEUU\"))\n",
    "         .drop(F.col(\"description\"))\n",
    ")\n",
    "\n",
    "CAvideosDF = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .option(\"quote\", \"\\\"\")\n",
    "         .option(\"escape\", \"\\\"\")\n",
    "         .csv(\"abfss://datos@masterhaoqx001sta.dfs.core.windows.net/youtube_CAvideos.csv\")\n",
    "         .withColumn(\"pais\", F.lit(\"CA\"))\n",
    "         .drop(F.col(\"description\"))\n",
    ")\n",
    "\n",
    "GBvideosDF = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"mode\", \"DROPMALFORMED\")\n",
    "         .option(\"quote\", \"\\\"\")\n",
    "         .option(\"escape\", \"\\\"\")\n",
    "         .csv(\"abfss://datos@masterhaoqx001sta.dfs.core.windows.net/youtube_GBvideos.csv\")\n",
    "         .withColumn(\"pais\", F.lit(\"GB\"))\n",
    "         .drop(F.col(\"description\"))\n",
    ")\n",
    "\n",
    "videosRawDF = (\n",
    "    USvideosDF.union(CAvideosDF)\n",
    "              .union(GBvideosDF)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3b57d3-dc5e-4138-a9c2-d89af33e12bc",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ebf649a36c3332710382e12e9b180c5",
     "grade": true,
     "grade_id": "read_csv_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert((videosRawDF.count() == 136992) | (videosRawDF.count() == 120750))\n",
    "assert(\"description\" not in videosRawDF.columns)\n",
    "assert((videosRawDF.where(\"pais = 'EEUU'\").count() == 48137) | (videosRawDF.where(\"pais = 'EEUU'\").count() == 40953))\n",
    "assert((videosRawDF.where(\"pais = 'CA'\").count() == 45560) | (videosRawDF.where(\"pais = 'CA'\").count() == 40881))\n",
    "assert((videosRawDF.where(\"pais = 'GB'\").count() == 43295) | (videosRawDF.where(\"pais = 'GB'\").count() == 38916))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "429f6d53-9b61-47f7-b525-9859f103a245",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0df0d8eca175055994c13960615d7bd1",
     "grade": false,
     "grade_id": "cell-b90f5b934eda250e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 2\n",
    "\n",
    "* Las columnas `trending_date` y `publish_time` son en realidad de tipo fecha y de tipo timestamp (instante de tiempo), respectivamente, que Spark debería procesar como tales. Por otro lado, `likes`, `dislikes`, `comment_count` son de tipo entero, y `comments_disabled` es de tipo booleano. La columna `category_id` también lo es pero la utilizaremos más adelante para reemplazarla por sus verdaderas categorías, por lo que no vamos a modificarla ahora y la mantenemos como string. Partiendo de `vidosRawDF`, **reemplaza** cada una de estas columnas por su versión convertida al tipo de dato correcto en cada caso, utilizando `withColumn` con el mismo nombre de la columna existente. Para las columnas de tipo fecha y timestamp, el nuevo valor de la columna viene dado por el siguiente código:\n",
    "\n",
    "        F.to_date(\"colName\", \"yy.dd.MM\") # para fechas\n",
    "        F.from_unixtime(F.unix_timestamp('colName', \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")).cast(\"timestamp\") # para timestamp\n",
    "\n",
    "* Después de las conversiones, eliminar todas las filas que tengan algún valor nulo\n",
    "* El DF resultante de todas estas operaciones debe quedar almacenado en la variable `videosDF`, **cacheado**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700f9f70-87d3-4989-a127-84c1f4b1b886",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n|   comments_disabled| count|\n+--------------------+------+\n|               False|118847|\n|                NULL| 16032|\n|    sports and more.|   145|\n|             Wiz Kid|     4|\n|                True|  1899|\n|            farfalle|    44|\n|        Ramsha Akmal|     1|\n|           Fida Daar|     3|\n|Ramsha Akmal as L...|    10|\n| but Carole’s bee...|     1|\n|              London|     2|\n|” she added.“She ...|     1|\n|            or black|     3|\n+--------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "videosRawDF.select(\"comments_disabled\").groupBy(\"comments_disabled\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7565ea36-4d40-44a0-a040-dbe7d2b71f0d",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cb06ef0eb82ebb70d1528083de619d2",
     "grade": false,
     "grade_id": "convert_timestamp",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# No olvides los imports que necesites...\n",
    "from pyspark.sql.types import IntegerType, BooleanType\n",
    "\n",
    "# LÍNEAS EVALUABLES, NO RENOMBRAR LAS VARIABLES\n",
    "videosDF = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "videosDF = (\n",
    "    videosRawDF.withColumn(\"trending_date\", F.to_date(F.col(\"trending_date\"), \"yy.dd.MM\"))\n",
    "               .withColumn(\"publish_time\", F.from_unixtime(F.unix_timestamp(F.col('publish_time'), \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")).cast(\"timestamp\"))\n",
    "               .withColumn(\"likes\", F.col(\"likes\").cast(IntegerType()))\n",
    "               .withColumn(\"dislikes\", F.col(\"dislikes\").cast(IntegerType()))\n",
    "               .withColumn(\"comment_count\", F.col(\"comment_count\").cast(IntegerType()))\n",
    "               .withColumn(\"comments_disabled\", F.col(\"comments_disabled\").cast(BooleanType()))\n",
    "               .na.drop(\"any\")\n",
    "               .cache()\n",
    "               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fdf42e7-08f2-49ee-909a-1e011c46df93",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a5e059625e1080585a339fbe73a68cf",
     "grade": true,
     "grade_id": "convert_timestamp_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dtypes = dict(videosDF.dtypes)\n",
    "assert((videosDF.count() == 120739) | (videosDF.count() == 120746))\n",
    "assert(dtypes[\"publish_time\"] == \"timestamp\")\n",
    "assert(dtypes[\"trending_date\"] == \"date\")\n",
    "assert(dtypes[\"likes\"] == \"int\")\n",
    "assert(dtypes[\"dislikes\"] == \"int\")\n",
    "assert(dtypes[\"comment_count\"] == \"int\")\n",
    "assert(dtypes[\"comments_disabled\"] == \"boolean\")\n",
    "assert(videosDF.is_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df10cf0f-1c3a-4dff-9fb8-8fd58c44dc8f",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8587dc30ffa23836889b4093a7fe5647",
     "grade": false,
     "grade_id": "cell-fc88821f19453a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(2 puntos)** Ejercicio 3\n",
    "\n",
    "Partiendo de `videosDF`:\n",
    "\n",
    "* Traduce la categoría a un string utilizando la equivalencia indicada en el diccionario de la celda siguiente. Para ello puedes usar directamente la función `videosDF.replace(to_replace=diccionario, subset=['category_id'])` **que se aplica al DF completo** y devuelve un DF completamente nuevo en el que ha realizado en las columnas especificadas en la lista `subset` los reemplazamientos que le hayamos indicado en el diccionario `to_replace`. Por tanto, esta función **no se utiliza en combinación con `withColumn`** sino que debe ir fuera de la secuencia de transformaciones encadenadas, por ejemplo al principio de todo, y su resultado debe almacenarse en la variable `replacedCategoryDF`.\n",
    "\n",
    "A continuación, partiendo de `replacedCategoryDF`: \n",
    "* Añade una nueva columna llamada `dias_hasta_viral` que contenga el número de días que han pasado entre la fecha en que se publicó un vídeo y el instante en el que se hizo viral. Para ello, utiliza `withColumn` en combinación con la función `F.datediff(\"columnaFuturo\", \"columnaPasado\")`\n",
    "* Añade otra nueva columna llamada `diasemana` que contenga el día de la semana en el que se ha publicado cada vídeo. Puedes usar la función `F.dayofweek(\"colName\")` en combinación con `withColumn`.\n",
    "* Vamos a empezar a utilizar la columna `tags`, para lo que necesitamos hacerla \"usable\". Encadenaremos estas tres transformaciones:\n",
    "  - El primer paso consiste en convertir todas las palabras en minúsculas, para que exista más coincidencia entre etiquetas y podamos ver que la misma aparece en varios vídeos. Puedes usar la función `F.lower(F.col(\"columnName\"))` en combinación con `withColumn` sobre la columna original. Atención: la función `lower` no admite directament el nombre de columna sino un objeto columna.\n",
    "  - El segundo paso será eliminar el carácter `\"` que rodea a la mayoría de términos individuales, puesto que no lo necesitamos ya que el separador entre términos es `|`. Puedes usar la función `F.regexp_replace(\"columnName\", \"\\\"\", \"\")` en combinación con `withColumn` sobre la salida del apartado anterior, o incluso simplemente envolver a `F.lower(...)` con `regexp_replace`: `F.regexp_replace(F.lower(...), \"\\\"\", \"\")`.\n",
    "  - El tercer paso consiste en convertirla en una columna de tipo **vector** de palabras, dividiendo la cadena de texto por el separador `|` que debe ser escapado poniendo una barra `\\` delante porque `|` se utiliza también en expresiones regulares. **Reemplaza** la columna `tags` por el resultado de aplicarle la función `F.split(\"colName\", \"\\|\")`. Dicha función debe ser utilizada dentro de `withColumn`.\n",
    "* El resultado debe quedar guardado en la variable `videosExtraInfoDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16d35175-f4fd-48b9-8058-7eae0c5cc5c0",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40913b4ab429e96be8be9d52bca1d398",
     "grade": false,
     "grade_id": "aniade_tiempos",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "# imports......\n",
    "diccionario = {\n",
    "   \"1\": \"Film & Animation\",\n",
    "   \"2\": \"Autos & Vehicles\",\n",
    "   \"10\": \"Music\",\n",
    "   \"15\": \"Pets & Animals\",\n",
    "   \"17\": \"Sports\",\n",
    "   \"18\": \"Short Movies\",\n",
    "   \"19\": \"Travel & Events\",\n",
    "   \"20\": \"Gaming\",\n",
    "   \"21\": \"Videoblogging\",\n",
    "   \"22\": \"People & Blogs\",\n",
    "   \"23\": \"Comedy\",\n",
    "   \"24\": \"Entertainment\",\n",
    "   \"25\": \"News & Politics\",\n",
    "   \"26\": \"Howto & Style\",\n",
    "   \"27\": \"Education\",\n",
    "   \"28\": \"Science & Technology\",\n",
    "   \"29\": \"Nonprofits & Activism\",\n",
    "   \"30\": \"Movies\",\n",
    "   \"31\": \"Anime/Animation\",\n",
    "   \"32\": \"Action/Adventure\",\n",
    "   \"33\": \"Classics\",\n",
    "   \"34\": \"Comedy\",\n",
    "   \"35\": \"Documentary\",\n",
    "   \"36\": \"Drama\",\n",
    "   \"37\": \"Family\",\n",
    "   \"38\": \"Foreign\",\n",
    "   \"39\": \"Horror\",\n",
    "   \"40\": \"Sci-Fi/Fantasy\",\n",
    "   \"41\": \"Thriller\",\n",
    "   \"42\": \"Shorts\",\n",
    "   \"43\": \"Shows\",\n",
    "   \"44\": \"Trailers\"\n",
    "}\n",
    "\n",
    "replacedCategoryDF = None\n",
    "videosExtraInfoDF = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "replacedCategoryDF = videosDF.replace(\n",
    "   to_replace=diccionario,\n",
    "   subset=['category_id']\n",
    ")\n",
    "\n",
    "videosExtraInfoDF = (\n",
    "   replacedCategoryDF.withColumn(\"dias_hasta_viral\", F.date_diff(end=\"trending_date\", start=\"publish_time\"))\n",
    "                     .withColumn(\"diasemana\", F.dayofweek(col=\"publish_time\"))\n",
    "                     .withColumn(\"tags\", F.regexp_replace(string=F.lower(F.col(\"tags\")), pattern=\"\\\"\", replacement=\"\"))\n",
    "                     .withColumn(\"tags\", F.split(str=\"tags\", pattern=\"\\|\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d086d0-d589-4d58-bd9c-aef007bcd4c4",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff264b92eb9345a26ec9470c4d3324db",
     "grade": true,
     "grade_id": "aniade_tiempos_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dtypesExtraInfo = dict(videosExtraInfoDF.dtypes)\n",
    "assert(dtypesExtraInfo[\"category_id\"] == \"string\")\n",
    "assert(dtypesExtraInfo[\"tags\"] == \"array<string>\")\n",
    "assert(dtypesExtraInfo[\"diasemana\"] == \"int\")\n",
    "assert(dtypesExtraInfo[\"dias_hasta_viral\"] == \"int\")\n",
    "assert(videosExtraInfoDF.where(\"category_id = 'Education'\").distinct().count() == 3103)\n",
    "r = videosExtraInfoDF.select(\"video_id\", \"category_id\", \"diasemana\", \"tags\").where(\"video_id == 'YVfyYrEmzgM'\").head()\n",
    "assert(r.category_id == \"Education\")\n",
    "assert(r.diasemana == 2)\n",
    "assert((\"ted\" in r.tags) & (\"ted-ed\" in r.tags) & (\"ted education\" in r.tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ff92b4-72d5-4f3a-9ae6-08aafa32a674",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "714aa44689924e527df8f805f4c3f65f",
     "grade": false,
     "grade_id": "cell-a71a6b17b1e0d613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 4\n",
    "\n",
    "Partiendo de `videosExtraInfoDF`:\n",
    "\n",
    "* Añadir una nueva columna `dias_viral_pais` que contenga el **número de días durante los cuales un vídeo ha sido tendencia en cada país**. El dataset original contiene en muchos casos varias filas para un mismo vídeo, incluso el mismo vídeo (mismo identificador) puede encontrarse en distintos países, variando en la columna relativa al día en que el vídeo es tendencia. Lo que se pide es que la nueva columna contenga, **para cada fila**, la **diferencia** en días entre la fecha **mínima y máxima** que ese vídeo ha sido tendencia **en ese país**. El valor en ambas columnas (mínima y máxima) se repetirá para todas las filas de cada vídeo y país, pero será distinto entre vídeos con distinto identificador y/o distinto país. Primero deben calcularse una columna para el mínimo y otra para el máximo por cada vídeo y país, **mediante agregaciones en una ventana (sin ordenar). No se debe utilizar la operación JOIN**. Una vez calculadas ambas columnas, la columna `dias_viral_pais` será el resultado de aplicarles la función `F.datediff` utilizada anteriormente, y tras ello, se deben eliminar las columnas de mínimo y máximo (si se hubieran llegado a crear) que ya no son necesarias.\n",
    "\n",
    "* Tras esto, eliminar las filas duplicadas, atendiendo exclusivamente a las columnas `video_id` y `pais`, puesto que la información de qué días fue tendencia ya la habremos resumido en la columna `dias_viral_pais`, y no queremos que cada vídeo aparezca varias veces y pueda falsear los resúmenes que haremos justo después. \n",
    "\n",
    "* El resultado de estos dos apartados debe almacenarse en la variable `videosDiasViralDF`, que **debe ser cacheada** porque  usaremos este DF varias veces más adelante.\n",
    "\n",
    "¿Son todas las categorías igual de viralizantes? ¿Además de la categoría, es distinto el comportamiento según el país?\n",
    "\n",
    "A continuación, y partiendo de `videosDiasViralDF`:\n",
    "\n",
    "* Calcular un nuevo DF llamado `diasViralCategoriaPaisDF` con tantas filas como **categorías** y con tantas columnas como **países** (es decir, 3 más la columna de categorías), que contenga en cada celda el número **medio** de días que un vídeo de cada categoría permanece siendo viral en ese país. PISTA: Utilizar la función **pivot**.\n",
    "\n",
    "* Por último, calcular otro DF llamado `videosPorDiasemanaDF` con tantas filas como **categorías** y tantas columnas como **días de la semana**, de forma que cada celda contenga el **número de vídeos DISTINTOS** que se han publicado en esa categoría ese día de la semana. Por vídeos distintos se entiende que **no** debemos contar varias veces un mismo vídeo (mismo `video_id`) ni siquiera si se ha publicado en distinto país. Tras el cálculo, **renombrar las columnas** para que sus nombres sean \"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\", \"Viernes\", \"Sábado\", \"Domingo\" en lugar de los números enteros del 1 al 7 (atención a las tildes). PISTA: piensa bien la función de agregación necesaria, y la columna sobre la que debe aplicarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e230be6d-bc37-408d-8459-c38648944514",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3375f7104b0af0e3b1d183bf207a932a",
     "grade": false,
     "grade_id": "categoria_pais_semana",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "# import.....\n",
    "ventanaVideoIdPais = None\n",
    "videosDiasViralDF = None\n",
    "diasViralCategoriaPaisDF = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "ventanaVideoIdPais = Window.partitionBy(\"video_id\", \"pais\")\n",
    "\n",
    "videosDiasViralDF = (\n",
    "    videosExtraInfoDF.withColumn(\"min_trending\", F.min(\"trending_date\").over(ventanaVideoIdPais))\n",
    "                     .withColumn(\"max_trending\", F.max(\"trending_date\").over(ventanaVideoIdPais))\n",
    "                     .withColumn(\"dias_viral_pais\", F.date_diff(end=\"max_trending\", start=\"min_trending\"))\n",
    "                     .drop(\"min_trending\", \"max_trending\")\n",
    "                     .dropDuplicates(subset=[\"video_id\", \"pais\"])\n",
    "                     .cache()\n",
    ")\n",
    "\n",
    "diasViralCategoriaPaisDF = (\n",
    "    videosDiasViralDF.groupBy(\"category_id\")\n",
    "                     .pivot(\"pais\")\n",
    "                     .agg(F.mean(\"dias_viral_pais\"))\n",
    ")\n",
    "\n",
    "dict_dias = {\n",
    "    \"1\" : \"Lunes\",\n",
    "    \"2\" : \"Martes\",\n",
    "    \"3\" : \"Miércoles\",\n",
    "    \"4\" : \"Jueves\",\n",
    "    \"5\" : \"Viernes\",\n",
    "    \"6\" : \"Sábado\",\n",
    "    \"7\" : \"Domingo\",\n",
    "}\n",
    "\n",
    "videosPorDiasemanaDF = (\n",
    "    videosDiasViralDF.groupBy(\"category_id\")\n",
    "                     .pivot(\"diasemana\")\n",
    "                     .agg(F.countDistinct(\"video_id\"))\n",
    "                     .withColumnsRenamed(colsMap=dict_dias)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e509ac73-2972-4eec-ab11-78c1d73c451a",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af67605ef5a72cd9a503158113c27a81",
     "grade": true,
     "grade_id": "categoria_pais_semana_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(videosDiasViralDF.is_cached)\n",
    "assert(dict(videosDiasViralDF.dtypes)[\"dias_viral_pais\"] == \"int\")\n",
    "assert((videosDiasViralDF.count() == 34045) | (videosDiasViralDF.count() == 34050))\n",
    "diasViralCategoriaPais = diasViralCategoriaPaisDF.sort(\"category_id\").collect()\n",
    "assert(diasViralCategoriaPais[0].category_id == \"Autos & Vehicles\")\n",
    "assert(round(diasViralCategoriaPais[0].CA, 3) == 0.431)\n",
    "assert(diasViralCategoriaPais[3].category_id == \"Entertainment\")\n",
    "assert(round(diasViralCategoriaPais[3].CA, 3) == 0.637)\n",
    "assert(\"Lunes\" in videosPorDiasemanaDF.columns)\n",
    "videosPorDiasemana = videosPorDiasemanaDF.sort(\"category_id\").collect()\n",
    "assert(videosPorDiasemana[0].Domingo == 18)\n",
    "assert(videosPorDiasemana[2].category_id == \"Education\")\n",
    "assert(videosPorDiasemana[2].Lunes == 108)\n",
    "assert(videosPorDiasemana[2].Sábado == 82)\n",
    "assert(videosDiasViralDF.where(\"video_id = 'f6Egj7ncOi8' and pais = 'CA'\").head().dias_viral_pais == 0)\n",
    "assert(videosDiasViralDF.where(\"video_id = 'f6Egj7ncOi8' and pais = 'GB'\").head().dias_viral_pais == 15)\n",
    "assert(videosDiasViralDF.where(\"video_id = 'f6Egj7ncOi8' and pais = 'EEUU'\").head().dias_viral_pais == 6)\n",
    "assert(\"Martes\" in videosPorDiasemanaDF.columns)\n",
    "assert(\"Miércoles\" in videosPorDiasemanaDF.columns)\n",
    "assert(\"Jueves\" in videosPorDiasemanaDF.columns)\n",
    "assert(\"Viernes\" in videosPorDiasemanaDF.columns)\n",
    "assert(\"Sábado\" in videosPorDiasemanaDF.columns)\n",
    "assert(\"Domingo\" in videosPorDiasemanaDF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4107b027-e6c7-4329-bfa2-3f8f55d2e536",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fae4edd71d48e509be1f633413181e90",
     "grade": false,
     "grade_id": "cell-c5ec05706eccd480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 5\n",
    "\n",
    "Partiendo de `videosDiasViralDF`, donde cada vídeo solo aparece una vez, añadir las siguientes columnas:\n",
    "\n",
    "* Una columna entera `ocurrencias_music` con el **número de ocurrencias** de la cadena **\"music\"** como **subcadena de cualquiera de los tags**. No es necesario que el tag sea exactamente igual a \"music\" sino que lo contenga como subcadena (recordemos que el DF de partida ya tiene todos los tags pasados a minúscula). Para ello, implementa una **UDF** `subtag_music_UDF` que devuelva `IntegerType()` y que envuelva a una función convencional de python llamada `subcadena_en_vector(tags)`. Esta última debe recibir como argumento una lista de strings, y comprobar cuántos elementos del vector contienen como subcadena a la palabra \"music\". Prueba su funcionamiento con la lista de tags `[\"a life in music\", \"music for life\", \"bso\", \"hans zimmer\"]` que debería devolver 2. Finalmente invoca a `subtag_music_UDF` dentro de `withColumn` sobre la columna `tags`.\n",
    "\n",
    "* Una columna `ocurrencia_media` de números reales con el número **medio** de apariciones de la palabra \"music\" como subcadena de tags en los vídeos similares al de la fila actual, entendiendo similares como aquellos del **mismo país y la misma categoría**. No debe utilizarse JOIN sino funciones de ventana.\n",
    "\n",
    "* Una nueva columna `diff_porcentaje` que indique, en tanto por ciento, en qué medida el número de aparticiones de \"music\" está por encima o por debajo de la media de los vídeos de su misma categoría y país. Debe calcularse mediante **operaciones aritméticas entre columnas**, sin usar la función `F.when`, como la diferencia entre el número de aparticiones en el vídeo actual menos las apariciones medias de su país y categoría, dividido entre este último y multiplicado por 100.\n",
    "\n",
    "El resultado de todas estas transformaciones debe quedar almacenado en la variable `videosOcurrenciasMusicDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05a05dfd-5770-46d7-a533-8feed65c7dec",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ece335cbbf1e5f177790021d4de04f",
     "grade": false,
     "grade_id": "ventana",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "# imports necesarios..........\n",
    "subtag_music = None\n",
    "\n",
    "def subcadena_en_vector(tags):\n",
    "    return (sum([1 for c in tags if \"music\" in c]))\n",
    "\n",
    "subtag_music_UDF = None\n",
    "ventanaCategoriaPais = None\n",
    "videosOcurrenciasMusicDF = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "subtag_music_UDF = F.udf(subcadena_en_vector, IntegerType())\n",
    "ventanaCategoriaPais = Window.partitionBy(\"category_id\", \"pais\")\n",
    "\n",
    "videosOcurrenciasMusicDF = (\n",
    "    videosDiasViralDF.withColumn(\"ocurrencias_music\", subtag_music_UDF(F.col(\"tags\")))\n",
    "                     .withColumn(\"ocurrencia_media\", F.mean(\"ocurrencias_music\").over(ventanaCategoriaPais))\n",
    "                     .withColumn(\"diff_porcentaje\", 100 * (F.col(\"ocurrencias_music\") - F.col(\"ocurrencia_media\")) / F.col(\"ocurrencia_media\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed88f43b-4de0-443f-a365-3691d3b56db9",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "377cef7708e3316c9047eedc4ec8d7bc",
     "grade": true,
     "grade_id": "ventana_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(subcadena_en_vector([\"a life in music\", \"music for life\", \"bso\", \"hans zimmer\"]) == 2)\n",
    "r = videosOcurrenciasMusicDF.where(\"video_id = 'uSVW0aJdn9o'\").head()\n",
    "assert(r.ocurrencias_music == 2)\n",
    "assert(r.ocurrencia_media - 1.0172278778386845 < 0.0001)\n",
    "assert(r.diff_porcentaje - 114.54046639231825 < 0.0001)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark_m5",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
